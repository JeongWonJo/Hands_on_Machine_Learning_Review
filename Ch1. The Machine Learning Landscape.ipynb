{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Machine Learning Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "training data with labels <br><br>\n",
    "**1. Classification:** <br>\n",
    "Predict a class of a sample\n",
    "<br><br>\n",
    "**2. Regression:**  <br>\n",
    "Predict a target value, given a set of features.\n",
    "    - K-Nearest Neighbors\n",
    "    - Linear Regression\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machines\n",
    "    - Decision Trees and Random Forests\n",
    "    - Neural Networks\n",
    "\n",
    "Regression algorithms can be used for classification as well, and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "unlabeled training data\n",
    "<br><br>\n",
    "**1. Clustering**\n",
    "    - K-Means: to detect similar samples\n",
    "    - Hierarchical Cluster Analysis: to subdivide each group into smaller groups\n",
    "    - Expectation Maximization: \n",
    "\n",
    "**2. Visualization and Dimensionality Reduction:**<br>\n",
    "    DR is to simplify the data w/o losing too much information; <br>\n",
    "    _feature extraction_ is to merge several correlated features into one.\n",
    "    - Principal Component Analysis:    \n",
    "    - Kernel PCA\n",
    "    - Locally-Linear Embedding\n",
    "    - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "**3. Anomaly Detection:**<br>\n",
    "    trained with normal instances; tell whether a new instance is normal or not\n",
    "\n",
    "**4. Association Rule Learning:** <br>\n",
    "    to dig into large amounts of data and discover interesting relations btw attributes\n",
    "    - Apriori\n",
    "    - Eclat\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semisupervised Learning\n",
    "partially labeled training data; <br>\n",
    "ie. **Deep Belief Networks (DBNs):** based on unsupervised components, _restricted Boltzmann machines_, which are fine-tuned using supervised learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "The learning system, agent, can observe the environment, select and perform actions, and get either rewards or penalties in turn. <br>\n",
    "It must learn by itself what is the best strategy, a policy, to get the most reward and take an action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Learning and Online Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Batch Learning | Online Learning | \n",
    "| :-------------: | :-------------: |\n",
    "| incapable of learning incrementally | train the system incrementally by feeding mini-batches |\n",
    "| should train the system from scratch when new data is given | good for data with continuous flow and need to adapt to change rapidly |\n",
    "| training with the full set of data takes a lot of time | huge datasets that cannot fit in one machine's main memeory |\n",
    "| detrimental when system has limited resources and data are huge | learning rate; how fast learning system adapts to changing data |\n",
    "| | performance will gradually decline when bad data is fed to the system |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance-based vs. Model-based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depends on how machine learning system generalize\n",
    "\n",
    "| Instance-based Learning | Model-based Learning | \n",
    "| :---: | :---: |\n",
    "| the system learns by memorizing the examples, <br> and generalizes to new data measuring a similarity | study the data, select a model, train it, <br> and apply the model to make predictions on new cases | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ie. Linear Model: y = theta1 + theta2 * x <br>\n",
    "to define the parameter values, theta1 and theta2, performance of each parameter value can be measured with a _utility function_ or a _cost function_. <br>\n",
    "For linear regression problems, a cost function, that measures the distance between the predicted value and the real value is often used. <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Challenges of Machine Learning\n",
    "## Bad Data\n",
    "### Insufficient Quantity of Training Data\n",
    "The trade-off between spending time and money on developing algorithm or on collecting data.\n",
    "\n",
    "### Nonrepresentative Training Data\n",
    "When data are nonrepresentative, it cannot generalize to new cases, failing to make accurate predictions. <br>\n",
    "Too small sample >> sampling noise <br>\n",
    "Flawed sampling method >> sampling bias <br>\n",
    "\n",
    "### Poor Quality Data\n",
    "Data full of errors, outliers, and noise and need cleaning; better to discard outliers or fix the errors manually. <br>\n",
    "\n",
    "### Irrelevant Features\n",
    "- _Feature Selection_: selecting the most useful features to train on\n",
    "- _Feature Extraction_: combining existing features to produce a more useful one or to reduce dimension\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Bad algorithms\n",
    "### Overfitting the Training Data\n",
    "Model performs well on the training data, but not on new data; cannot generalize well.<br>\n",
    "_Regularization_: constraining a model to make it simpler and reduce the risk of overfitting <br>\n",
    "All about balance between fitting the data perfectly and keeping the model simple. <br>\n",
    "<br>\n",
    "_hyperparameter_: a parameter of a learning algorithm. controls the amount of regularization to apply during learning. <br>\n",
    "\n",
    "### Underfitting the Training Data\n",
    "Model being too simple to learn the underlying structure of the data.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Validating\n",
    "Split data into two sets: the training set and the test set. <br><br>\n",
    "The error rate on new cases is the _generalization error_. If the training error is low but the generalization error is high, the model is overfitting the training data.\n",
    "\n",
    "Suppose you train 100 models on the equivalent data set with 100 hyperparameter values and found the optimal value that returns low error.<br>\n",
    "If you apply the model to new set, the generalization error may be high unlike your prediction. It's because you made a model with hyperparameter that are optimized for the test set. <br>\n",
    "<br>\n",
    "_validation set_: train multiple models with various hyperparameters using the training set >> select the model and hyperparameter that perform best on the validation set\n",
    "<br>\n",
    "<br>\n",
    "_cross-validation_: not to lose too large volume of data as a validation set. \n",
    "1. Split training set into subsets and each model is trained on a different combination of these subsets and validated against the remaining parts.\n",
    "2. Select the model type and hyperparameters\n",
    "3. Final model with optimal hyperparameter value is trained on the full training set, and the generalized error is measured on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
